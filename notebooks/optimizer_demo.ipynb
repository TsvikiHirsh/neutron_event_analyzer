{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Association Parameter Optimizer Demo\n",
    "\n",
    "This notebook demonstrates how to use the `AssociationOptimizer` to find optimal association parameters for your data.\n",
    "\n",
    "The optimizer automatically tests different association methods and parameters, comparing results to ground truth data to find the best configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Import the optimizer\n",
    "from neutron_event_analyzer.optimizer import (\n",
    "    AssociationOptimizer,\n",
    "    AssociationMetrics,\n",
    "    optimize_for_synthetic_data\n",
    ")\n",
    "\n",
    "# Import synthetic data generation functions\n",
    "sys.path.insert(0, str(Path('../tests')))\n",
    "from test_association_validation import (\n",
    "    create_synthetic_photon_data,\n",
    "    create_synthetic_event_data,\n",
    "    write_csv_files\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Basic Grid Search\n",
    "\n",
    "Let's start with a simple example: find the best association method and parameters for well-separated events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define synthetic events\n",
    "event_configs = [\n",
    "    {\n",
    "        'event_id': 0,\n",
    "        'center_x': 50.0,\n",
    "        'center_y': 50.0,\n",
    "        't_ns': 1000.0,\n",
    "        'n_photons': 8,\n",
    "        'photon_spread_spatial': 15.0,  # Moderate spatial spread\n",
    "        'photon_spread_temporal': 50.0   # Moderate temporal spread\n",
    "    },\n",
    "    {\n",
    "        'event_id': 1,\n",
    "        'center_x': 150.0,\n",
    "        'center_y': 150.0,\n",
    "        't_ns': 10000.0,\n",
    "        'n_photons': 8,\n",
    "        'photon_spread_spatial': 15.0,\n",
    "        'photon_spread_temporal': 50.0\n",
    "    },\n",
    "    {\n",
    "        'event_id': 2,\n",
    "        'center_x': 200.0,\n",
    "        'center_y': 100.0,\n",
    "        't_ns': 20000.0,\n",
    "        'n_photons': 8,\n",
    "        'photon_spread_spatial': 15.0,\n",
    "        'photon_spread_temporal': 50.0\n",
    "    }\n",
    "]\n",
    "\n",
    "# Generate synthetic data\n",
    "photon_df = create_synthetic_photon_data(event_configs)\n",
    "event_df = create_synthetic_event_data(event_configs)\n",
    "\n",
    "print(f\"Created {len(event_configs)} events with {len(photon_df)} photons total\")\n",
    "print(f\"\\nPhoton data preview:\")\n",
    "print(photon_df.head())\n",
    "print(f\"\\nEvent data preview:\")\n",
    "print(event_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporary directory for data\n",
    "tmpdir = tempfile.mkdtemp()\n",
    "data_path = Path(tmpdir) / \"data\"\n",
    "data_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Write CSV files\n",
    "write_csv_files(None, photon_df, event_df, data_path, file_index=0)\n",
    "\n",
    "print(f\"Synthetic data written to: {data_path}\")\n",
    "print(f\"\\nFiles created:\")\n",
    "for file in sorted(data_path.glob('*')):\n",
    "    print(f\"  - {file.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize optimizer\n",
    "optimizer = AssociationOptimizer(\n",
    "    synthetic_data_dir=str(data_path),\n",
    "    ground_truth_photons=photon_df,\n",
    "    ground_truth_events=event_df,\n",
    "    verbosity=1  # Show progress\n",
    ")\n",
    "\n",
    "# Run grid search\n",
    "best = optimizer.grid_search(\n",
    "    methods=['simple', 'kdtree'],\n",
    "    spatial_thresholds_px=[10.0, 20.0, 30.0, 50.0],\n",
    "    temporal_thresholds_ns=[50.0, 100.0, 200.0, 500.0],\n",
    "    metric='f1_score'\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Best Parameters Found:\")\n",
    "print(\"=\"*70)\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Visualize Results\n",
    "\n",
    "Let's examine all the results to understand the parameter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results to DataFrame for easy analysis\n",
    "results_df = pd.DataFrame([r.to_dict() for r in optimizer.results])\n",
    "\n",
    "print(f\"Tested {len(results_df)} parameter combinations\\n\")\n",
    "print(\"Top 10 configurations by F1 score:\")\n",
    "print(results_df.sort_values('f1_score', ascending=False)[[\n",
    "    'method', 'spatial_threshold_px', 'temporal_threshold_ns', \n",
    "    'f1_score', 'accuracy', 'association_rate'\n",
    "]].head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze by method\n",
    "print(\"\\nPerformance by method:\")\n",
    "print(\"=\"*70)\n",
    "for method in results_df['method'].unique():\n",
    "    method_results = results_df[results_df['method'] == method]\n",
    "    best_for_method = method_results.loc[method_results['f1_score'].idxmax()]\n",
    "    print(f\"\\n{method}:\")\n",
    "    print(f\"  Best F1 Score: {best_for_method['f1_score']:.4f}\")\n",
    "    print(f\"  Best Spatial: {best_for_method['spatial_threshold_px']:.1f} px\")\n",
    "    print(f\"  Best Temporal: {best_for_method['temporal_threshold_ns']:.1f} ns\")\n",
    "    print(f\"  Accuracy: {best_for_method['accuracy']:.2%}\")\n",
    "    print(f\"  Association Rate: {best_for_method['association_rate']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Save Best Parameters\n",
    "\n",
    "Export the best parameters in a format that can be used with your analysis pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best parameters in empir format\n",
    "best_params = optimizer.get_best_parameters_json()\n",
    "\n",
    "print(\"Best parameters in empir/NEA format:\")\n",
    "print(json.dumps(best_params, indent=2))\n",
    "\n",
    "# Save to file\n",
    "output_path = Path(tmpdir) / \"optimized_parameters.json\"\n",
    "optimizer.save_best_parameters(str(output_path))\n",
    "\n",
    "print(f\"\\nParameters saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Recursive Optimization\n",
    "\n",
    "If you already have good starting parameters, you can fine-tune them using recursive optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start from the grid search result and fine-tune\n",
    "print(\"Starting recursive optimization from grid search result...\\n\")\n",
    "\n",
    "best_recursive = optimizer.recursive_optimize(\n",
    "    method='simple',\n",
    "    initial_spatial_px=best.spatial_threshold_px,\n",
    "    initial_temporal_ns=best.temporal_threshold_ns,\n",
    "    max_iterations=5,\n",
    "    convergence_threshold=0.001,\n",
    "    metric='f1_score'\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Comparison: Grid Search vs Recursive Optimization\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nGrid Search:\")\n",
    "print(f\"  Spatial: {best.spatial_threshold_px:.2f} px\")\n",
    "print(f\"  Temporal: {best.temporal_threshold_ns:.2f} ns\")\n",
    "print(f\"  F1 Score: {best.f1_score:.4f}\")\n",
    "print(f\"\\nRecursive Optimization:\")\n",
    "print(f\"  Spatial: {best_recursive.spatial_threshold_px:.2f} px\")\n",
    "print(f\"  Temporal: {best_recursive.temporal_threshold_ns:.2f} ns\")\n",
    "print(f\"  F1 Score: {best_recursive.f1_score:.4f}\")\n",
    "print(f\"\\nImprovement: {(best_recursive.f1_score - best.f1_score):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: Optimize for Different Scenarios\n",
    "\n",
    "Let's test optimization for different types of clustering patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = {\n",
    "    'Tight Clustering': {\n",
    "        'event_id': 0,\n",
    "        'center_x': 100.0,\n",
    "        'center_y': 100.0,\n",
    "        't_ns': 1000.0,\n",
    "        'n_photons': 10,\n",
    "        'photon_spread_spatial': 5.0,   # Very tight\n",
    "        'photon_spread_temporal': 20.0\n",
    "    },\n",
    "    'Loose Clustering': {\n",
    "        'event_id': 0,\n",
    "        'center_x': 100.0,\n",
    "        'center_y': 100.0,\n",
    "        't_ns': 1000.0,\n",
    "        'n_photons': 10,\n",
    "        'photon_spread_spatial': 50.0,  # Very loose\n",
    "        'photon_spread_temporal': 200.0\n",
    "    },\n",
    "    'Moderate Clustering': {\n",
    "        'event_id': 0,\n",
    "        'center_x': 100.0,\n",
    "        'center_y': 100.0,\n",
    "        't_ns': 1000.0,\n",
    "        'n_photons': 10,\n",
    "        'photon_spread_spatial': 20.0,\n",
    "        'photon_spread_temporal': 80.0\n",
    "    }\n",
    "}\n",
    "\n",
    "scenario_results = {}\n",
    "\n",
    "for scenario_name, config in scenarios.items():\n",
    "    print(f\"\\nOptimizing for: {scenario_name}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Create synthetic data\n",
    "    photon_df_scenario = create_synthetic_photon_data([config])\n",
    "    event_df_scenario = create_synthetic_event_data([config])\n",
    "    \n",
    "    # Write to temporary directory\n",
    "    scenario_path = Path(tmpdir) / scenario_name.replace(' ', '_')\n",
    "    scenario_path.mkdir(exist_ok=True)\n",
    "    write_csv_files(None, photon_df_scenario, event_df_scenario, scenario_path, file_index=0)\n",
    "    \n",
    "    # Optimize\n",
    "    scenario_optimizer = AssociationOptimizer(\n",
    "        synthetic_data_dir=str(scenario_path),\n",
    "        ground_truth_photons=photon_df_scenario,\n",
    "        ground_truth_events=event_df_scenario,\n",
    "        verbosity=0  # Silent for comparison\n",
    "    )\n",
    "    \n",
    "    best_scenario = scenario_optimizer.grid_search(\n",
    "        methods=['simple'],\n",
    "        spatial_thresholds_px=[5.0, 10.0, 20.0, 50.0, 100.0],\n",
    "        temporal_thresholds_ns=[20.0, 50.0, 100.0, 200.0, 500.0],\n",
    "        metric='f1_score'\n",
    "    )\n",
    "    \n",
    "    scenario_results[scenario_name] = best_scenario\n",
    "    \n",
    "    print(f\"  Best Spatial: {best_scenario.spatial_threshold_px:.1f} px\")\n",
    "    print(f\"  Best Temporal: {best_scenario.temporal_threshold_ns:.1f} ns\")\n",
    "    print(f\"  F1 Score: {best_scenario.f1_score:.4f}\")\n",
    "    print(f\"  Association Rate: {best_scenario.association_rate:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare scenarios\n",
    "print(\"\\nScenario Comparison:\")\n",
    "print(\"=\"*90)\n",
    "print(f\"{'Scenario':<20} {'Spatial (px)':<15} {'Temporal (ns)':<15} {'F1 Score':<12} {'Assoc Rate':<12}\")\n",
    "print(\"-\"*90)\n",
    "\n",
    "for scenario_name, result in scenario_results.items():\n",
    "    print(f\"{scenario_name:<20} {result.spatial_threshold_px:<15.1f} \"\n",
    "          f\"{result.temporal_threshold_ns:<15.1f} \"\n",
    "          f\"{result.f1_score:<12.4f} \"\n",
    "          f\"{result.association_rate:<12.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 6: Using Convenience Function\n",
    "\n",
    "The `optimize_for_synthetic_data` function provides a quick way to run optimization and save results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new synthetic data\n",
    "quick_configs = [\n",
    "    {\n",
    "        'event_id': i,\n",
    "        'center_x': 50.0 + i * 80.0,\n",
    "        'center_y': 50.0 + i * 60.0,\n",
    "        't_ns': 1000.0 + i * 5000.0,\n",
    "        'n_photons': 7,\n",
    "        'photon_spread_spatial': 18.0,\n",
    "        'photon_spread_temporal': 60.0\n",
    "    }\n",
    "    for i in range(3)\n",
    "]\n",
    "\n",
    "quick_photon_df = create_synthetic_photon_data(quick_configs)\n",
    "quick_event_df = create_synthetic_event_data(quick_configs)\n",
    "\n",
    "quick_data_path = Path(tmpdir) / \"quick_test\"\n",
    "quick_output_path = Path(tmpdir) / \"quick_results\"\n",
    "quick_data_path.mkdir(exist_ok=True)\n",
    "\n",
    "write_csv_files(None, quick_photon_df, quick_event_df, quick_data_path, file_index=0)\n",
    "\n",
    "# One-line optimization with file output\n",
    "best_quick = optimize_for_synthetic_data(\n",
    "    synthetic_data_dir=str(quick_data_path),\n",
    "    ground_truth_photons=quick_photon_df,\n",
    "    ground_truth_events=quick_event_df,\n",
    "    mode='grid',\n",
    "    output_dir=str(quick_output_path),\n",
    "    verbosity=1,\n",
    "    methods=['simple'],\n",
    "    spatial_thresholds_px=[10.0, 20.0, 30.0],\n",
    "    temporal_thresholds_ns=[50.0, 100.0, 200.0]\n",
    ")\n",
    "\n",
    "print(f\"\\nResults saved to: {quick_output_path}\")\n",
    "print(\"Files created:\")\n",
    "for file in sorted(quick_output_path.glob('*')):\n",
    "    print(f\"  - {file.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Grid Search**: Systematically test parameter combinations\n",
    "2. **Result Analysis**: Examine and compare all tested configurations\n",
    "3. **Parameter Export**: Save optimal parameters for use in analysis\n",
    "4. **Recursive Optimization**: Fine-tune parameters from a starting point\n",
    "5. **Scenario Comparison**: Test different clustering patterns\n",
    "6. **Convenience Function**: Quick one-line optimization with file output\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Create synthetic data that matches your real data characteristics\n",
    "- Run optimization to find best parameters\n",
    "- Export parameters and use them in your analysis pipeline\n",
    "- Validate on real data\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- Full documentation: `docs/OPTIMIZER.md`\n",
    "- Example scripts: `notebooks/example_optimizer_usage.py`\n",
    "- Tests: `tests/test_association_optimizer.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup temporary directory\n",
    "import shutil\n",
    "shutil.rmtree(tmpdir)\n",
    "print(f\"Cleaned up temporary directory: {tmpdir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
